{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "from timm.data.loader import MultiEpochsDataLoader\n",
    "\n",
    "from model import *\n",
    "from data_loader import LoadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mounted-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfgs = {\"name\": \"DL20\", \"num_classes\": 20, \"dir\":\"./data/DL20\"}\n",
    "train_cfgs = {\"batch_size\": 128, \"lr\": 0.0001}\n",
    "\n",
    "### load small version of ResNet\n",
    "model = Small_ResNet(BasicBlock, [3, 3, 3], num_classes=data_cfgs['num_classes']).to('cuda')\n",
    "\n",
    "### load train/valid/test dataset\n",
    "train_dataset = LoadDataset(data_cfgs[\"dir\"], mode=\"train\", random_flip=True)\n",
    "valid_dataset = LoadDataset(data_cfgs[\"dir\"], mode=\"valid\", random_flip=False)\n",
    "# test_dataset = LoadDataset(data_cfgs[\"dir\"], mode=\"test\", random_flip=False)\n",
    "\n",
    "### warp dataset using dataloader\n",
    "train_dataloader = MultiEpochsDataLoader(train_dataset, batch_size=train_cfgs[\"batch_size\"], shuffle=True, pin_memory=True, drop_last=True, num_workers=64)\n",
    "valid_dataloader = MultiEpochsDataLoader(valid_dataset, batch_size=train_cfgs[\"batch_size\"], shuffle=False, pin_memory=True, drop_last=False, num_workers=64)\n",
    "# test_dataloader = MultiEpochsDataLoader(test_dataset, batch_size=train_cfgs[\"batch_size\"], shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "### define Adam optimizer: one of the popular optimizers in Deep Learning community\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), train_cfgs[\"lr\"], eps=1e-6)\n",
    "\n",
    "### define cross-entropy loss for classification\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "official-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, patience, num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    mean_train_losses = []\n",
    "    mean_valid_losses = [] \n",
    "    p = 0\n",
    "    min_valid_loss = 100\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "        model.train() \n",
    "        for train_data, target in train_dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device(\"cuda\")\n",
    "                train_data, target = train_data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval() \n",
    "        for valid_data, target in valid_dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device(\"cuda\")\n",
    "                valid_data, target = valid_data.to(device), target.to(device)\n",
    "            output = model(valid_data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        mean_train_losses.append(train_loss)\n",
    "        mean_valid_losses.append(valid_loss)\n",
    "        \n",
    "        if min_valid_loss > valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            # print(f'min_valid_loss: {min_valid_loss}')\n",
    "\n",
    "        epoch_len = len(str(num_epochs))\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        print(print_msg)\n",
    "        \n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        if min_valid_loss < valid_loss and epoch > 1:\n",
    "            p = p + 1\n",
    "            #print(f'patience: {p}')\n",
    "        else:\n",
    "            p = 0\n",
    "            torch.save(model.state_dict(), 'bestmodel.pt')\n",
    "            print(\"Saving Model...\")\n",
    "        \n",
    "        if patience == p:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('bestmodel.pt'))\n",
    "\n",
    "    return  model, mean_train_losses, mean_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incredible-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "def print_test_accuracy(model, test_loader):\n",
    "  class_correct = list(0. for i in range(20))\n",
    "  class_total = list(0. for i in range(20))\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for test_data, target in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            test_data, target = test_data.to(device), target.to(device)\n",
    "        output = model(test_data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        c = np.squeeze(predicted.eq(target.data.view_as(predicted)))\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "  model.apply(weight_reset)\n",
    "\n",
    "  print('Test Accuracy (Total): %.2f %% (%d/%d)\\n' % (\n",
    "      100. * np.sum(class_correct) / np.sum(class_total),\n",
    "      np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "motivated-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1/1000] train_loss: 3.00670 valid_loss: 2.92339\n",
      "Saving Model...\n",
      "[   2/1000] train_loss: 2.82268 valid_loss: 2.75782\n",
      "Saving Model...\n",
      "[   3/1000] train_loss: 2.70124 valid_loss: 2.65968\n",
      "Saving Model...\n",
      "[   4/1000] train_loss: 2.61736 valid_loss: 2.59399\n",
      "Saving Model...\n",
      "[   5/1000] train_loss: 2.54196 valid_loss: 2.55143\n",
      "Saving Model...\n",
      "[   6/1000] train_loss: 2.47795 valid_loss: 2.52382\n",
      "Saving Model...\n",
      "[   7/1000] train_loss: 2.42264 valid_loss: 2.49832\n",
      "Saving Model...\n",
      "[   8/1000] train_loss: 2.38474 valid_loss: 2.47033\n",
      "Saving Model...\n",
      "[   9/1000] train_loss: 2.34093 valid_loss: 2.41841\n",
      "Saving Model...\n",
      "[  10/1000] train_loss: 2.30655 valid_loss: 2.42585\n",
      "[  11/1000] train_loss: 2.27170 valid_loss: 2.34237\n",
      "Saving Model...\n",
      "[  12/1000] train_loss: 2.23674 valid_loss: 2.34554\n",
      "[  13/1000] train_loss: 2.21481 valid_loss: 2.31239\n",
      "Saving Model...\n",
      "[  14/1000] train_loss: 2.18919 valid_loss: 2.30041\n",
      "Saving Model...\n",
      "[  15/1000] train_loss: 2.15754 valid_loss: 2.27747\n",
      "Saving Model...\n",
      "[  16/1000] train_loss: 2.13579 valid_loss: 2.25288\n",
      "Saving Model...\n",
      "[  17/1000] train_loss: 2.11335 valid_loss: 2.23393\n",
      "Saving Model...\n",
      "[  18/1000] train_loss: 2.09116 valid_loss: 2.22238\n",
      "Saving Model...\n",
      "[  19/1000] train_loss: 2.07336 valid_loss: 2.17625\n",
      "Saving Model...\n",
      "[  20/1000] train_loss: 2.03942 valid_loss: 2.18531\n",
      "[  21/1000] train_loss: 2.02302 valid_loss: 2.15367\n",
      "Saving Model...\n",
      "[  22/1000] train_loss: 1.99882 valid_loss: 2.15192\n",
      "Saving Model...\n",
      "[  23/1000] train_loss: 1.97982 valid_loss: 2.14206\n",
      "Saving Model...\n",
      "[  24/1000] train_loss: 1.96761 valid_loss: 2.11063\n",
      "Saving Model...\n",
      "[  25/1000] train_loss: 1.94739 valid_loss: 2.09362\n",
      "Saving Model...\n",
      "[  26/1000] train_loss: 1.92076 valid_loss: 2.08580\n",
      "Saving Model...\n",
      "[  27/1000] train_loss: 1.90756 valid_loss: 2.07462\n",
      "Saving Model...\n",
      "[  28/1000] train_loss: 1.89462 valid_loss: 2.05061\n",
      "Saving Model...\n",
      "[  29/1000] train_loss: 1.88225 valid_loss: 2.05865\n",
      "[  30/1000] train_loss: 1.86517 valid_loss: 2.03007\n",
      "Saving Model...\n",
      "[  31/1000] train_loss: 1.84229 valid_loss: 2.01977\n",
      "Saving Model...\n",
      "[  32/1000] train_loss: 1.83801 valid_loss: 1.99909\n",
      "Saving Model...\n",
      "[  33/1000] train_loss: 1.82188 valid_loss: 2.01829\n",
      "[  34/1000] train_loss: 1.79739 valid_loss: 2.01121\n",
      "[  35/1000] train_loss: 1.78890 valid_loss: 1.99734\n",
      "Saving Model...\n",
      "[  36/1000] train_loss: 1.77057 valid_loss: 1.97777\n",
      "Saving Model...\n",
      "[  37/1000] train_loss: 1.76342 valid_loss: 1.98868\n",
      "[  38/1000] train_loss: 1.75455 valid_loss: 1.98235\n",
      "[  39/1000] train_loss: 1.73684 valid_loss: 1.93030\n",
      "Saving Model...\n",
      "[  40/1000] train_loss: 1.72150 valid_loss: 1.96657\n",
      "[  41/1000] train_loss: 1.70657 valid_loss: 1.96063\n",
      "[  42/1000] train_loss: 1.69466 valid_loss: 1.93838\n",
      "[  43/1000] train_loss: 1.68502 valid_loss: 1.93369\n",
      "[  44/1000] train_loss: 1.67099 valid_loss: 1.96750\n",
      "[  45/1000] train_loss: 1.66271 valid_loss: 1.91887\n",
      "Saving Model...\n",
      "[  46/1000] train_loss: 1.64285 valid_loss: 1.94357\n",
      "[  47/1000] train_loss: 1.63040 valid_loss: 1.90138\n",
      "Saving Model...\n",
      "[  48/1000] train_loss: 1.62886 valid_loss: 1.93165\n",
      "[  49/1000] train_loss: 1.61371 valid_loss: 1.90849\n",
      "[  50/1000] train_loss: 1.60480 valid_loss: 1.90379\n",
      "[  51/1000] train_loss: 1.58613 valid_loss: 1.91165\n",
      "[  52/1000] train_loss: 1.56981 valid_loss: 1.88434\n",
      "Saving Model...\n",
      "[  53/1000] train_loss: 1.56263 valid_loss: 1.92091\n",
      "[  54/1000] train_loss: 1.56585 valid_loss: 1.89273\n",
      "[  55/1000] train_loss: 1.54917 valid_loss: 1.88366\n",
      "Saving Model...\n",
      "[  56/1000] train_loss: 1.53628 valid_loss: 1.89394\n",
      "[  57/1000] train_loss: 1.51847 valid_loss: 1.89124\n",
      "[  58/1000] train_loss: 1.50791 valid_loss: 1.86892\n",
      "Saving Model...\n",
      "[  59/1000] train_loss: 1.49991 valid_loss: 1.88436\n",
      "[  60/1000] train_loss: 1.48228 valid_loss: 1.89969\n",
      "[  61/1000] train_loss: 1.47759 valid_loss: 1.84159\n",
      "Saving Model...\n",
      "[  62/1000] train_loss: 1.47169 valid_loss: 1.88157\n",
      "[  63/1000] train_loss: 1.46916 valid_loss: 1.85329\n",
      "[  64/1000] train_loss: 1.45095 valid_loss: 1.84941\n",
      "[  65/1000] train_loss: 1.43017 valid_loss: 1.88629\n",
      "[  66/1000] train_loss: 1.42506 valid_loss: 1.85968\n",
      "[  67/1000] train_loss: 1.41838 valid_loss: 1.88811\n",
      "[  68/1000] train_loss: 1.40951 valid_loss: 1.87738\n",
      "[  69/1000] train_loss: 1.40008 valid_loss: 1.85044\n",
      "[  70/1000] train_loss: 1.37928 valid_loss: 1.85741\n",
      "[  71/1000] train_loss: 1.37160 valid_loss: 1.87467\n",
      "[  72/1000] train_loss: 1.37297 valid_loss: 1.88762\n",
      "[  73/1000] train_loss: 1.35473 valid_loss: 1.86506\n",
      "[  74/1000] train_loss: 1.34795 valid_loss: 1.84481\n",
      "[  75/1000] train_loss: 1.33353 valid_loss: 1.90646\n",
      "[  76/1000] train_loss: 1.32567 valid_loss: 1.83871\n",
      "Saving Model...\n",
      "[  77/1000] train_loss: 1.32363 valid_loss: 1.83695\n",
      "Saving Model...\n",
      "[  78/1000] train_loss: 1.30602 valid_loss: 1.85331\n",
      "[  79/1000] train_loss: 1.29183 valid_loss: 1.81812\n",
      "Saving Model...\n",
      "[  80/1000] train_loss: 1.27341 valid_loss: 1.87426\n",
      "[  81/1000] train_loss: 1.28014 valid_loss: 1.85239\n",
      "[  82/1000] train_loss: 1.26683 valid_loss: 1.86003\n",
      "[  83/1000] train_loss: 1.24429 valid_loss: 1.83900\n",
      "[  84/1000] train_loss: 1.24063 valid_loss: 1.84787\n",
      "[  85/1000] train_loss: 1.23241 valid_loss: 1.86849\n",
      "[  86/1000] train_loss: 1.22941 valid_loss: 1.86056\n",
      "[  87/1000] train_loss: 1.22552 valid_loss: 1.83661\n",
      "[  88/1000] train_loss: 1.21135 valid_loss: 1.86402\n",
      "[  89/1000] train_loss: 1.20161 valid_loss: 1.87624\n",
      "[  90/1000] train_loss: 1.19080 valid_loss: 1.87744\n",
      "[  91/1000] train_loss: 1.17758 valid_loss: 1.86891\n",
      "[  92/1000] train_loss: 1.16564 valid_loss: 1.90884\n",
      "[  93/1000] train_loss: 1.16820 valid_loss: 1.86804\n",
      "[  94/1000] train_loss: 1.14576 valid_loss: 1.84140\n",
      "Early stopping\n",
      "Test Accuracy (Total): 45.83 % (764/1667)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "patience = 15\n",
    "\n",
    "final_model, train_losses, valid_losses= train_model(model, patience, num_epochs)\n",
    "print_test_accuracy(final_model, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-header",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
